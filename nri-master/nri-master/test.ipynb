{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def load_data(batch_size=1, suffix=''):\n",
    "    loc_train = np.load('data/loc_train' + suffix + '.npy')\n",
    "    vel_train = np.load('data/vel_train' + suffix + '.npy')\n",
    "    edges_train = np.load('data/edges_train' + suffix + '.npy')\n",
    "\n",
    "    loc_valid = np.load('data/loc_valid' + suffix + '.npy')\n",
    "    vel_valid = np.load('data/vel_valid' + suffix + '.npy')\n",
    "    edges_valid = np.load('data/edges_valid' + suffix + '.npy')\n",
    "\n",
    "    loc_test = np.load('data/loc_test' + suffix + '.npy')\n",
    "    vel_test = np.load('data/vel_test' + suffix + '.npy')\n",
    "    edges_test = np.load('data/edges_test' + suffix + '.npy')\n",
    "\n",
    "    # [num_samples, num_timesteps, num_dims, num_atoms]\n",
    "    num_atoms = loc_train.shape[3]\n",
    "    #print(loc_train.size())\n",
    "    loc_max = loc_train.max()\n",
    "    loc_min = loc_train.min()\n",
    "    vel_max = vel_train.max()\n",
    "    vel_min = vel_train.min()\n",
    "\n",
    "    # Normalize to [-1, 1]\n",
    "    loc_train = (loc_train - loc_min) * 2 / (loc_max - loc_min) - 1\n",
    "    vel_train = (vel_train - vel_min) * 2 / (vel_max - vel_min) - 1\n",
    "\n",
    "    loc_valid = (loc_valid - loc_min) * 2 / (loc_max - loc_min) - 1\n",
    "    vel_valid = (vel_valid - vel_min) * 2 / (vel_max - vel_min) - 1\n",
    "\n",
    "    loc_test = (loc_test - loc_min) * 2 / (loc_max - loc_min) - 1\n",
    "    vel_test = (vel_test - vel_min) * 2 / (vel_max - vel_min) - 1\n",
    "\n",
    "    # Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "    loc_train = np.transpose(loc_train, [0, 3, 1, 2])\n",
    "    print(loc_train.shape)\n",
    "    vel_train = np.transpose(vel_train, [0, 3, 1, 2])\n",
    "    print(vel_train.shape)\n",
    "    feat_train = np.concatenate([loc_train, vel_train], axis=3)\n",
    "    print(feat_train.shape)\n",
    "    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])\n",
    "    print(edges_train.shape)\n",
    "    print(edges_train[:5,:])\n",
    "\n",
    "    # 为什么???\n",
    "    edges_train = np.array((edges_train + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    loc_valid = np.transpose(loc_valid, [0, 3, 1, 2])\n",
    "    vel_valid = np.transpose(vel_valid, [0, 3, 1, 2])\n",
    "    feat_valid = np.concatenate([loc_valid, vel_valid], axis=3)\n",
    "    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])\n",
    "    edges_valid = np.array((edges_valid + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    loc_test = np.transpose(loc_test, [0, 3, 1, 2])\n",
    "    vel_test = np.transpose(vel_test, [0, 3, 1, 2])\n",
    "    feat_test = np.concatenate([loc_test, vel_test], axis=3)\n",
    "    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])\n",
    "    edges_test = np.array((edges_test + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    feat_train = torch.FloatTensor(feat_train)\n",
    "    edges_train = torch.LongTensor(edges_train)\n",
    "    feat_valid = torch.FloatTensor(feat_valid)\n",
    "    edges_valid = torch.LongTensor(edges_valid)\n",
    "    feat_test = torch.FloatTensor(feat_test)\n",
    "    edges_test = torch.LongTensor(edges_test)\n",
    "\n",
    "    # Exclude self edges\n",
    "    off_diag_idx = np.ravel_multi_index(\n",
    "        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),\n",
    "        [num_atoms, num_atoms])\n",
    "    print(off_diag_idx)\n",
    "    edges_train = edges_train[:, off_diag_idx]\n",
    "    edges_valid = edges_valid[:, off_diag_idx]\n",
    "    edges_test = edges_test[:, off_diag_idx]\n",
    "\n",
    "    train_data = TensorDataset(feat_train, edges_train)\n",
    "    valid_data = TensorDataset(feat_valid, edges_valid)\n",
    "    test_data = TensorDataset(feat_test, edges_test)\n",
    "\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "    test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_data_loader, valid_data_loader, test_data_loader, loc_max, loc_min, vel_max, vel_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def my_softmax(input, axis=1):\n",
    "    trans_input = input.transpose(axis, 0).contiguous()\n",
    "    soft_max_1d = F.softmax(trans_input)\n",
    "    return soft_max_1d.transpose(axis, 0)\n",
    "\n",
    "\n",
    "def binary_concrete(logits, tau=1, hard=False, eps=1e-10):\n",
    "    y_soft = binary_concrete_sample(logits, tau=tau, eps=eps)\n",
    "    if hard:\n",
    "        y_hard = (y_soft > 0.5).float()\n",
    "        y = Variable(y_hard.data - y_soft.data) + y_soft\n",
    "    else:\n",
    "        y = y_soft\n",
    "    return y\n",
    "\n",
    "\n",
    "def binary_concrete_sample(logits, tau=1, eps=1e-10):\n",
    "    logistic_noise = sample_logistic(logits.size(), eps=eps)\n",
    "    if logits.is_cuda:\n",
    "        logistic_noise = logistic_noise.cuda()\n",
    "    y = logits + Variable(logistic_noise)\n",
    "    return F.sigmoid(y / tau)\n",
    "\n",
    "\n",
    "def sample_logistic(shape, eps=1e-10):\n",
    "    uniform = torch.rand(shape).float()\n",
    "    return torch.log(uniform + eps) - torch.log(1 - uniform + eps)\n",
    "\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Sample from Gumbel(0, 1)\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    U = torch.rand(shape).float()\n",
    "    return - torch.log(eps - torch.log(U + eps))\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Draw a sample from the Gumbel-Softmax distribution\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
    "    if logits.is_cuda:\n",
    "        gumbel_noise = gumbel_noise.cuda()\n",
    "    y = logits + Variable(gumbel_noise)\n",
    "    return my_softmax(y / tau, axis=-1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "      logits: [batch_size, n_class] unnormalized log-probs\n",
    "      tau: non-negative scalar temperature\n",
    "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "      be a probability distribution that sums to 1 across classes\n",
    "\n",
    "    Constraints:\n",
    "    - this implementation only works on batch_size x num_features tensor for now\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
    "    if hard:\n",
    "        shape = logits.size()\n",
    "        _, k = y_soft.data.max(-1)\n",
    "        # this bit is based on\n",
    "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
    "        y_hard = torch.zeros(*shape)\n",
    "        if y_soft.is_cuda:\n",
    "            y_hard = y_hard.cuda()\n",
    "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
    "        # this cool bit of code achieves two things:\n",
    "        # - makes the output value exactly one-hot (since we add then\n",
    "        #   subtract y_soft value)\n",
    "        # - makes the gradient equal to y_soft gradient (since we strip\n",
    "        #   all other gradients)\n",
    "        y = Variable(y_hard - y_soft.data) + y_soft\n",
    "    else:\n",
    "        y = y_soft\n",
    "    return y\n",
    "\n",
    "\n",
    "def binary_accuracy(output, labels):\n",
    "    preds = output > 0.5\n",
    "    correct = preds.type_as(labels).eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def load_data(batch_size=1, suffix=''):\n",
    "    loc_train = np.load('data/loc_train' + suffix + '.npy')\n",
    "    vel_train = np.load('data/vel_train' + suffix + '.npy')\n",
    "    edges_train = np.load('data/edges_train' + suffix + '.npy')\n",
    "\n",
    "    loc_valid = np.load('data/loc_valid' + suffix + '.npy')\n",
    "    vel_valid = np.load('data/vel_valid' + suffix + '.npy')\n",
    "    edges_valid = np.load('data/edges_valid' + suffix + '.npy')\n",
    "\n",
    "    loc_test = np.load('data/loc_test' + suffix + '.npy')\n",
    "    vel_test = np.load('data/vel_test' + suffix + '.npy')\n",
    "    edges_test = np.load('data/edges_test' + suffix + '.npy')\n",
    "\n",
    "    # [num_samples, num_timesteps, num_dims, num_atoms]\n",
    "    num_atoms = loc_train.shape[3]\n",
    "\n",
    "    loc_max = loc_train.max()\n",
    "    loc_min = loc_train.min()\n",
    "    vel_max = vel_train.max()\n",
    "    vel_min = vel_train.min()\n",
    "\n",
    "    # Normalize to [-1, 1]\n",
    "    loc_train = (loc_train - loc_min) * 2 / (loc_max - loc_min) - 1\n",
    "    vel_train = (vel_train - vel_min) * 2 / (vel_max - vel_min) - 1\n",
    "\n",
    "    loc_valid = (loc_valid - loc_min) * 2 / (loc_max - loc_min) - 1\n",
    "    vel_valid = (vel_valid - vel_min) * 2 / (vel_max - vel_min) - 1\n",
    "\n",
    "    loc_test = (loc_test - loc_min) * 2 / (loc_max - loc_min) - 1\n",
    "    vel_test = (vel_test - vel_min) * 2 / (vel_max - vel_min) - 1\n",
    "\n",
    "    # Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "    loc_train = np.transpose(loc_train, [0, 3, 1, 2])\n",
    "    vel_train = np.transpose(vel_train, [0, 3, 1, 2])\n",
    "    feat_train = np.concatenate([loc_train, vel_train], axis=3)\n",
    "    edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])\n",
    "    edges_train = np.array((edges_train + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    loc_valid = np.transpose(loc_valid, [0, 3, 1, 2])\n",
    "    vel_valid = np.transpose(vel_valid, [0, 3, 1, 2])\n",
    "    feat_valid = np.concatenate([loc_valid, vel_valid], axis=3)\n",
    "    edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])\n",
    "    edges_valid = np.array((edges_valid + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    loc_test = np.transpose(loc_test, [0, 3, 1, 2])\n",
    "    vel_test = np.transpose(vel_test, [0, 3, 1, 2])\n",
    "    feat_test = np.concatenate([loc_test, vel_test], axis=3)\n",
    "    edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])\n",
    "    edges_test = np.array((edges_test + 1) / 2, dtype=np.int64)\n",
    "\n",
    "    feat_train = torch.FloatTensor(feat_train)\n",
    "    edges_train = torch.LongTensor(edges_train)\n",
    "    feat_valid = torch.FloatTensor(feat_valid)\n",
    "    edges_valid = torch.LongTensor(edges_valid)\n",
    "    feat_test = torch.FloatTensor(feat_test)\n",
    "    edges_test = torch.LongTensor(edges_test)\n",
    "\n",
    "    # Exclude self edges\n",
    "    off_diag_idx = np.ravel_multi_index(\n",
    "        np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),\n",
    "        [num_atoms, num_atoms])\n",
    "    edges_train = edges_train[:, off_diag_idx]\n",
    "    edges_valid = edges_valid[:, off_diag_idx]\n",
    "    edges_test = edges_test[:, off_diag_idx]\n",
    "\n",
    "    train_data = TensorDataset(feat_train, edges_train)\n",
    "    valid_data = TensorDataset(feat_valid, edges_valid)\n",
    "    test_data = TensorDataset(feat_test, edges_test)\n",
    "\n",
    "    train_data_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "    test_data_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_data_loader, valid_data_loader, test_data_loader, loc_max, loc_min, vel_max, vel_min\n",
    "\n",
    "def to_2d_idx(idx, num_cols):\n",
    "    idx = np.array(idx, dtype=np.int64)\n",
    "    y_idx = np.array(np.floor(idx / float(num_cols)), dtype=np.int64)\n",
    "    x_idx = idx % num_cols\n",
    "    return x_idx, y_idx\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def get_triu_indices(num_nodes):\n",
    "    \"\"\"Linear triu (upper triangular) indices.\"\"\"\n",
    "    ones = torch.ones(num_nodes, num_nodes)\n",
    "    eye = torch.eye(num_nodes, num_nodes)\n",
    "    triu_indices = (ones.triu() - eye).nonzero().t()\n",
    "    triu_indices = triu_indices[0] * num_nodes + triu_indices[1]\n",
    "    return triu_indices\n",
    "\n",
    "\n",
    "def get_tril_indices(num_nodes):\n",
    "    \"\"\"Linear tril (lower triangular) indices.\"\"\"\n",
    "    ones = torch.ones(num_nodes, num_nodes)\n",
    "    eye = torch.eye(num_nodes, num_nodes)\n",
    "    tril_indices = (ones.tril() - eye).nonzero().t()\n",
    "    tril_indices = tril_indices[0] * num_nodes + tril_indices[1]\n",
    "    return tril_indices\n",
    "\n",
    "\n",
    "def get_offdiag_indices(num_nodes):\n",
    "    \"\"\"Linear off-diagonal indices.\"\"\"\n",
    "    ones = torch.ones(num_nodes, num_nodes)\n",
    "    eye = torch.eye(num_nodes, num_nodes)\n",
    "    offdiag_indices = (ones - eye).nonzero().t()\n",
    "    offdiag_indices = offdiag_indices[0] * num_nodes + offdiag_indices[1]\n",
    "    return offdiag_indices\n",
    "\n",
    "\n",
    "def get_triu_offdiag_indices(num_nodes):\n",
    "    \"\"\"Linear triu (upper) indices w.r.t. vector of off-diagonal elements.\"\"\"\n",
    "    triu_idx = torch.zeros(num_nodes * num_nodes)\n",
    "    triu_idx[get_triu_indices(num_nodes)] = 1.\n",
    "    triu_idx = triu_idx[get_offdiag_indices(num_nodes)]\n",
    "    return triu_idx.nonzero()\n",
    "\n",
    "\n",
    "def get_tril_offdiag_indices(num_nodes):\n",
    "    \"\"\"Linear tril (lower) indices w.r.t. vector of off-diagonal elements.\"\"\"\n",
    "    tril_idx = torch.zeros(num_nodes * num_nodes)\n",
    "    tril_idx[get_tril_indices(num_nodes)] = 1.\n",
    "    tril_idx = tril_idx[get_offdiag_indices(num_nodes)]\n",
    "    return tril_idx.nonzero()\n",
    "\n",
    "\n",
    "def get_minimum_distance(data):\n",
    "    data = data[:, :, :, :2].transpose(1, 2)\n",
    "    data_norm = (data ** 2).sum(-1, keepdim=True)\n",
    "    dist = data_norm + \\\n",
    "           data_norm.transpose(2, 3) - \\\n",
    "           2 * torch.matmul(data, data.transpose(2, 3))\n",
    "    min_dist, _ = dist.min(1)\n",
    "    return min_dist.view(min_dist.size(0), -1)\n",
    "\n",
    "\n",
    "def get_buckets(dist, num_buckets):\n",
    "    dist = dist.cpu().data.numpy()\n",
    "\n",
    "    min_dist = np.min(dist)\n",
    "    max_dist = np.max(dist)\n",
    "    bucket_size = (max_dist - min_dist) / num_buckets\n",
    "    thresholds = bucket_size * np.arange(num_buckets)\n",
    "\n",
    "    bucket_idx = []\n",
    "    for i in range(num_buckets):\n",
    "        if i < num_buckets - 1:\n",
    "            idx = np.where(np.all(np.vstack((dist > thresholds[i],\n",
    "                                             dist <= thresholds[i + 1])), 0))[0]\n",
    "        else:\n",
    "            idx = np.where(dist > thresholds[i])[0]\n",
    "        bucket_idx.append(idx)\n",
    "\n",
    "    return bucket_idx, thresholds\n",
    "\n",
    "\n",
    "def get_correct_per_bucket(bucket_idx, pred, target):\n",
    "    pred = pred.cpu().numpy()[:, 0]\n",
    "    target = target.cpu().data.numpy()\n",
    "\n",
    "    correct_per_bucket = []\n",
    "    for i in range(len(bucket_idx)):\n",
    "        preds_bucket = pred[bucket_idx[i]]\n",
    "        target_bucket = target[bucket_idx[i]]\n",
    "        correct_bucket = np.sum(preds_bucket == target_bucket)\n",
    "        correct_per_bucket.append(correct_bucket)\n",
    "\n",
    "    return correct_per_bucket\n",
    "\n",
    "\n",
    "def get_correct_per_bucket_(bucket_idx, pred, target):\n",
    "    pred = pred.cpu().numpy()\n",
    "    target = target.cpu().data.numpy()\n",
    "\n",
    "    correct_per_bucket = []\n",
    "    for i in range(len(bucket_idx)):\n",
    "        preds_bucket = pred[bucket_idx[i]]\n",
    "        target_bucket = target[bucket_idx[i]]\n",
    "        correct_bucket = np.sum(preds_bucket == target_bucket)\n",
    "        correct_per_bucket.append(correct_bucket)\n",
    "\n",
    "    return correct_per_bucket\n",
    "\n",
    "\n",
    "def kl_categorical(preds, log_prior, num_atoms, eps=1e-16):\n",
    "    kl_div = preds * (torch.log(preds + eps) - log_prior)\n",
    "    return kl_div.sum() / (num_atoms * preds.size(0))\n",
    "\n",
    "\n",
    "def kl_categorical_uniform(preds, num_atoms, num_edge_types, add_const=False,\n",
    "                           eps=1e-16):\n",
    "    kl_div = preds * torch.log(preds + eps)\n",
    "    if add_const:\n",
    "        const = np.log(num_edge_types)\n",
    "        kl_div += const\n",
    "    return kl_div.sum() / (num_atoms * preds.size(0))\n",
    "\n",
    "\n",
    "def nll_gaussian(preds, target, variance, add_const=False):\n",
    "    neg_log_p = ((preds - target) ** 2 / (2 * variance))\n",
    "    if add_const:\n",
    "        const = 0.5 * np.log(2 * np.pi * variance)\n",
    "        neg_log_p += const\n",
    "    return neg_log_p.sum() / (target.size(0) * target.size(1))\n",
    "\n",
    "\n",
    "def edge_accuracy(preds, target):\n",
    "    _, preds = preds.max(-1)\n",
    "    correct = preds.float().data.eq(\n",
    "        target.float().data.view_as(preds)).cpu().sum()\n",
    "    return np.float(correct) / (target.size(0) * target.size(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader, loc_max, loc_min, vel_max, vel_min = load_data(\n",
    "    32, '_springs5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Generate off-diagonal interaction graph\n",
    "off_diag = np.ones([5, 5]) - np.eye(5)\n",
    "\n",
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)\n",
    "print(rel_rec)\n",
    "print(rel_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from utils import my_softmax, get_offdiag_indices, gumbel_softmax\n",
    "\n",
    "_EPS = 1e-10\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc2 = nn.Linear(n_hid, n_out)\n",
    "        self.bn = nn.BatchNorm1d(n_out)\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def batch_norm(self, inputs):\n",
    "        x = inputs.view(inputs.size(0) * inputs.size(1), -1)\n",
    "        x = self.bn(x)\n",
    "        return x.view(inputs.size(0), inputs.size(1), -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Input shape: [num_sims, num_things, num_features]\n",
    "        x = F.elu(self.fc1(inputs))\n",
    "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        return self.batch_norm(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(CNN, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=None, padding=0,\n",
    "                                 dilation=1, return_indices=False,\n",
    "                                 ceil_mode=False)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(n_in, n_hid, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hid)\n",
    "        self.conv2 = nn.Conv1d(n_hid, n_hid, kernel_size=5, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hid)\n",
    "        self.conv_predict = nn.Conv1d(n_hid, n_out, kernel_size=1)\n",
    "        self.conv_attention = nn.Conv1d(n_hid, 1, kernel_size=1)\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Input shape: [num_sims * num_edges, num_dims, num_timesteps]\n",
    "\n",
    "        x = F.relu(self.conv1(inputs))\n",
    "        x = self.bn1(x)\n",
    "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        pred = self.conv_predict(x)\n",
    "        attention = my_softmax(self.conv_attention(x), axis=2)\n",
    "\n",
    "        edge_prob = (pred * attention).mean(dim=2)\n",
    "        return edge_prob\n",
    "\n",
    "\n",
    "class MLPEncoder(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0., factor=True):\n",
    "        super(MLPEncoder, self).__init__()\n",
    "\n",
    "        self.factor = factor\n",
    "\n",
    "        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)\n",
    "        self.mlp2 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "        self.mlp3 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        if self.factor:\n",
    "            self.mlp4 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
    "            print(\"Using factor graph MLP encoder.\")\n",
    "        else:\n",
    "            self.mlp4 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "            print(\"Using MLP encoder.\")\n",
    "        self.fc_out = nn.Linear(n_hid, n_out)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def edge2node(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        incoming = torch.matmul(rel_rec.t(), x)\n",
    "        return incoming / incoming.size(1)\n",
    "\n",
    "    def node2edge(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        edges = torch.cat([senders, receivers], dim=2)\n",
    "        return edges\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "        # num_sims维相当于Batch_size\n",
    "\n",
    "        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        x = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
    "\n",
    "        x = self.mlp1(x)  # 2-layer ELU net per node\n",
    "\n",
    "        x = self.node2edge(x, rel_rec, rel_send)\n",
    "        x = self.mlp2(x)\n",
    "        x_skip = x\n",
    "\n",
    "        if self.factor:\n",
    "            x = self.edge2node(x, rel_rec, rel_send)\n",
    "            x = self.mlp3(x)\n",
    "            x = self.node2edge(x, rel_rec, rel_send)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp4(x)\n",
    "        else:\n",
    "            x = self.mlp3(x)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp4(x)\n",
    "\n",
    "        return self.fc_out(x)\n",
    "\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0., factor=True):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "        self.factor = factor\n",
    "\n",
    "        self.cnn = CNN(n_in * 2, n_hid, n_hid, do_prob)\n",
    "        self.mlp1 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        self.mlp2 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        self.mlp3 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
    "        self.fc_out = nn.Linear(n_hid, n_out)\n",
    "\n",
    "        if self.factor:\n",
    "            print(\"Using factor graph CNN encoder.\")\n",
    "        else:\n",
    "            print(\"Using CNN encoder.\")\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def node2edge_temporal(self, inputs, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "\n",
    "        x = inputs.view(inputs.size(0), inputs.size(1), -1)\n",
    "        #print('x:', x.size())\n",
    "        #print('rel_rec:', rel_rec.size())\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        #print('1:', receivers.size())\n",
    "        receivers = receivers.view(inputs.size(0) * receivers.size(1),\n",
    "                                   inputs.size(2), inputs.size(3))\n",
    "        #print('2:', receivers.size())\n",
    "        receivers = receivers.transpose(2, 1)\n",
    "        #print('3:', receivers.size())\n",
    "\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        senders = senders.view(inputs.size(0) * senders.size(1),\n",
    "                               inputs.size(2),\n",
    "                               inputs.size(3))\n",
    "        senders = senders.transpose(2, 1)\n",
    "\n",
    "        # receivers and senders have shape:\n",
    "        # [num_sims * num_edges, num_dims, num_timesteps]\n",
    "        edges = torch.cat([senders, receivers], dim=1)\n",
    "        return edges\n",
    "\n",
    "    def edge2node(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        #print('x:', x.size())\n",
    "        incoming = torch.matmul(rel_rec.t(), x)\n",
    "        return incoming / incoming.size(1)\n",
    "\n",
    "    def node2edge(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        edges = torch.cat([senders, receivers], dim=2)\n",
    "        return edges\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "\n",
    "        # Input has shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        edges = self.node2edge_temporal(inputs, rel_rec, rel_send)\n",
    "        x = self.cnn(edges)\n",
    "        #print(x.size())\n",
    "        x = x.view(inputs.size(0), (inputs.size(1) - 1) * inputs.size(1), -1)\n",
    "        x = self.mlp1(x)\n",
    "        #print(x.size())\n",
    "        x_skip = x\n",
    "\n",
    "        if self.factor:\n",
    "            x = self.edge2node(x, rel_rec, rel_send)\n",
    "            #print(x.size())\n",
    "            x = self.mlp2(x)\n",
    "            #print(x.size())\n",
    "\n",
    "            x = self.node2edge(x, rel_rec, rel_send)\n",
    "            #print(x.size())\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            #print(x.size())\n",
    "            x = self.mlp3(x)\n",
    "            #print(x.size())\n",
    "\n",
    "        return self.fc_out(x)\n",
    "\n",
    "class MLPDecoder(nn.Module):\n",
    "    \"\"\"MLP decoder module.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, msg_hid, msg_out, n_hid,\n",
    "                 do_prob=0., skip_first=False):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)])\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])\n",
    "        self.msg_out_shape = msg_out\n",
    "        self.skip_first_edge_type = skip_first\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print('Using learned interaction net decoder.')\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, single_timestep_inputs, rel_rec, rel_send,\n",
    "                            single_timestep_rel_type):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "        #print(pre_msg.size())\n",
    "        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
    "                                        pre_msg.size(2), self.msg_out_shape))\n",
    "        if single_timestep_inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "        else:\n",
    "            start_idx = 0\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exlude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.relu(self.msg_fc2[i](msg))\n",
    "            msg = msg * single_timestep_rel_type[:, :, :, i:i + 1]\n",
    "            all_msgs += msg\n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred\n",
    "\n",
    "    def forward(self, inputs, rel_type, rel_rec, rel_send, pred_steps=1):\n",
    "        # 这里有个假设，所有样本的图都是一样的\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        # inputs.shape = [B, N, T, d]\n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "        # now = [B, T, N, d]\n",
    "        sizes = [rel_type.size(0), inputs.size(1), rel_type.size(1),\n",
    "                 rel_type.size(2)]\n",
    "        #  sizes.shape = [B, T, 20, 2] 20是边的数量，2是边类型\n",
    "        # 将原来的边edges.shape = [B, 20, 2]按照T扩展成 \n",
    "        # rel_type.shape = [B, T, 20, 2]\n",
    "        rel_type = rel_type.unsqueeze(1).expand(sizes)\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert (pred_steps <= time_steps)\n",
    "        preds = []\n",
    "\n",
    "        # Only take n-th timesteps as starting points (n: pred_steps)\n",
    "        last_pred = inputs[:, 0::pred_steps, :, :]\n",
    "        # print(last_pred.size())# [B, 5, 5, 4]\n",
    "        curr_rel_type = rel_type[:, 0::pred_steps, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps):\n",
    "            last_pred = self.single_step_forward(last_pred, rel_rec, rel_send,\n",
    "                                                 curr_rel_type)\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [preds[0].size(0), preds[0].size(1) * pred_steps,\n",
    "                 preds[0].size(2), preds[0].size(3)]\n",
    "\n",
    "        output = Variable(torch.zeros(sizes))\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)):\n",
    "            output[:, i::pred_steps, :, :] = preds[i]\n",
    "\n",
    "        pred_all = output[:, :(inputs.size(1) - 1), :, :]\n",
    "        #print(pred_all.size())\n",
    "        return pred_all.transpose(1, 2).contiguous()\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    \"\"\"Recurrent decoder module.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, n_hid,\n",
    "                 do_prob=0., skip_first=False):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_hid, n_hid) for _ in range(edge_types)])\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(n_hid, n_hid) for _ in range(edge_types)])\n",
    "        self.msg_out_shape = n_hid\n",
    "        self.skip_first_edge_type = skip_first\n",
    "\n",
    "        self.hidden_r = nn.Linear(n_hid, n_hid, bias=False)\n",
    "        self.hidden_i = nn.Linear(n_hid, n_hid, bias=False)\n",
    "        self.hidden_h = nn.Linear(n_hid, n_hid, bias=False)\n",
    "\n",
    "        self.input_r = nn.Linear(n_in_node, n_hid, bias=True)\n",
    "        self.input_i = nn.Linear(n_in_node, n_hid, bias=True)\n",
    "        self.input_n = nn.Linear(n_in_node, n_hid, bias=True)\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print('Using learned recurrent interaction net decoder.')\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, inputs, rel_rec, rel_send,\n",
    "                            rel_type, hidden):\n",
    "\n",
    "        # node2edge\n",
    "        receivers = torch.matmul(rel_rec, hidden)\n",
    "        senders = torch.matmul(rel_send, hidden)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
    "                                        self.msg_out_shape))\n",
    "        if inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "            norm = float(len(self.msg_fc2)) - 1.\n",
    "        else:\n",
    "            start_idx = 0\n",
    "            norm = float(len(self.msg_fc2))\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exlude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            msg = F.tanh(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.tanh(self.msg_fc2[i](msg))\n",
    "            print(msg.size(), '*', rel_type.size())\n",
    "            msg = msg * rel_type[:, :, i:i + 1]\n",
    "            print(msg.size())\n",
    "            all_msgs += msg / norm\n",
    "\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2,\n",
    "                                                                        -1)\n",
    "        agg_msgs = agg_msgs.contiguous() / inputs.size(2)  # Average\n",
    "\n",
    "        # GRU-style gated aggregation\n",
    "        r = F.sigmoid(self.input_r(inputs) + self.hidden_r(agg_msgs))\n",
    "        i = F.sigmoid(self.input_i(inputs) + self.hidden_i(agg_msgs))\n",
    "        n = F.tanh(self.input_n(inputs) + r * self.hidden_h(agg_msgs))\n",
    "        hidden = (1 - i) * n + i * hidden\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(hidden)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        pred = inputs + pred\n",
    "\n",
    "        return pred, hidden\n",
    "\n",
    "    def forward(self, data, rel_type, rel_rec, rel_send, pred_steps=1,\n",
    "                burn_in=False, burn_in_steps=1, dynamic_graph=False,\n",
    "                encoder=None, temp=None):\n",
    "\n",
    "        inputs = data.transpose(1, 2).contiguous()\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "\n",
    "        # inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # rel_type has shape:\n",
    "        # [batch_size, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        hidden = Variable(\n",
    "            torch.zeros(inputs.size(0), inputs.size(2), self.msg_out_shape))\n",
    "        if inputs.is_cuda:\n",
    "            hidden = hidden.cuda()\n",
    "\n",
    "        pred_all = []\n",
    "\n",
    "        for step in range(0, inputs.size(1) - 1):\n",
    "\n",
    "            if burn_in:\n",
    "                if step <= burn_in_steps:\n",
    "                    ins = inputs[:, step, :, :]\n",
    "                else:\n",
    "                    ins = pred_all[step - 1]\n",
    "            else:\n",
    "                assert (pred_steps <= time_steps)\n",
    "                # Use ground truth trajectory input vs. last prediction\n",
    "                if not step % pred_steps:\n",
    "                    ins = inputs[:, step, :, :]\n",
    "                else:\n",
    "                    ins = pred_all[step - 1]\n",
    "            # 动态图可以用于交通流预测\n",
    "            if dynamic_graph and step >= burn_in_steps:\n",
    "                # NOTE: Assumes burn_in_steps = args.timesteps\n",
    "                logits = encoder(\n",
    "                    data[:, :, step - burn_in_steps:step, :].contiguous(),\n",
    "                    rel_rec, rel_send)\n",
    "                rel_type = gumbel_softmax(logits, tau=temp, hard=True)\n",
    "\n",
    "            pred, hidden = self.single_step_forward(ins, rel_rec, rel_send,\n",
    "                                                    rel_type, hidden)\n",
    "            pred_all.append(pred)\n",
    "\n",
    "        preds = torch.stack(pred_all, dim=1)\n",
    "\n",
    "        return preds.transpose(1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using factor graph CNN encoder.\n",
      "Using learned recurrent interaction net decoder.\n"
     ]
    }
   ],
   "source": [
    "encoder = CNNEncoder(4, 128,\n",
    "                         2,\n",
    "                         0, True)\n",
    "\n",
    "decoder = RNNDecoder(n_in_node=4,\n",
    "                         edge_types=2,\n",
    "                         n_hid=128,\n",
    "                         do_prob=0,\n",
    "                         skip_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HCheng\\Desktop\\图卷积\\Project\\nri-master\\nri-master\\utils.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  soft_max_1d = F.softmax(trans_input)\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20, 2])\n",
      "torch.Size([32, 5, 49, 4])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n",
      "torch.Size([32, 20, 128]) * torch.Size([32, 20, 2])\n",
      "torch.Size([32, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "    rel_rec = Variable(rel_rec)\n",
    "    rel_send = Variable(rel_send)\n",
    "    logits = encoder(data, rel_rec, rel_send)\n",
    "    edges = gumbel_softmax(logits, tau=0.5, hard=False)\n",
    "    #prob = my_softmax(logits, -1)\n",
    "    print(edges.size())\n",
    "    print(data.size())\n",
    "    output = decoder(data, edges, rel_rec, rel_send, 100, burn_in=True, burn_in_steps=39)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "527a93331b4b1a8345148922acc34427fb7591433d63b66d32040b6fbbc6d593"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
